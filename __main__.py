import uuid
import boto3



def create_bucket_name(bucket_prefix):
    """
    returnes a unique name for an s3-bucket
    requires a prefix for the unique name
    """
    return ''.join([bucket_prefix, str(uuid.uuid4())])

def create_bucket(bucket_prefix, s3_connection):
    """
    creates a s3 bucket
    returnes 2 variables:
      "bucket_name" is the unique name 
       generated by the "create_bucket_name" function
      "bucket_response" is a dictionary containing 
       information about the created s3-bucket 
    requires:
      "bucket_prefix" the prefix for the bucket's name
      "s3_connection" the connection type client/resource (could be either
       low level or high level)
    """
    session = boto3.session.Session()
    current_region = session.region_name
    bucket_name = create_bucket_name(bucket_prefix)
    bucket_response = s3_connection.create_bucket(
        Bucket=bucket_name,
        CreateBucketConfiguration={
        'LocationConstraint': current_region})
    print(bucket_name, current_region)
    return bucket_name, bucket_response

def create_temp_file(size, file_name, file_content):
    """
    returns a variable containing a file with a unique name
    requires:
        size - number of times the file_content will
               be multiplied inside the same file
        file_name - prefix for your unique file name
        file_content - data that will be inserted to the file
    """
    random_file_name = ''.join([str(uuid.uuid4().hex[:6]), file_name])
    with open(random_file_name, 'w') as f:
        f.write(str(file_content) * size)
    return random_file_name

def copy_to_bucket(bucket_from_name, bucket_to_name, file_name):
    """
    need to add docstring
    """
    copy_source = {
        'Bucket': bucket_from_name,
        'Key': file_name
    }
    s3_resource.Object(bucket_to_name, file_name).copy(copy_source)


                              #                 #
                             ##                 ##
                            ###  start of code  ###
                             ##                 ##
                              #                 #


s3_client = boto3.client('s3')
s3_resource = boto3.resource('s3')

# creating two buckets, the first with a "client" connection type
# and the second with a "resource" connection type

first_bucket_name, first_response = create_bucket(
    bucket_prefix='firstpythonbucket', 
    s3_connection=s3_resource.meta.client)

second_bucket_name, second_response = create_bucket(      
    bucket_prefix='secondpythonbucket', s3_connection=s3_resource)


# creating a file by calling to the "create_temp_file" function:
first_file_name = create_temp_file(300, 'firstfile.txt', 'f')   

first_bucket = s3_resource.Bucket(name=first_bucket_name)
first_object = s3_resource.Object(
    bucket_name=first_bucket_name, key=first_file_name)

first_object.upload_file(first_file_name)

s3_resource.Object(first_bucket_name, first_file_name).download_file(
    f'/tmp/{first_file_name}')

copy_to_bucket(first_bucket_name, second_bucket_name, first_file_name)

s3_resource.Object(second_bucket_name, first_file_name).delete()

second_file_name = create_temp_file(400, 'secondfile.txt', 's')
second_object = s3_resource.Object(first_bucket.name, second_file_name)
second_object.upload_file(second_file_name, ExtraArgs={
                          'ACL': 'public-read'})
